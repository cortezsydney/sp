#1
lm1 <- lm(my_data$Y ~ my_data$X, data=my_data)
#coef(lm1)
#summary(lm1)
#confint(lm1)
pl  + geom_abline(intercept=coef(lm1)[1],slope=coef(lm1)[2],size=1, colour="#339900")
#par(mfrow = c(1, 2))
#plot(lm1, which=c(1,2))
set.seed(100)
n <- nrow(my_data)
i.training <- sort(sample(n,round(n*0.8)))
my_data.training <- my_data[i.training,]
my_data.test  <- my_data[-i.training,]
pred1a.test <- predict(lm1, newdata=my_data.test)
lm1.training <- lm(my_data$Y ~ my_data$X, data=my_data.training)
pred1b.test <- predict(lm1.training, newdata=my_data.test)
data.frame(my_data, pred1a.test, pred1b.test)
dist.test <- my_data.test$X
my_data <- read.csv("test.csv", header=FALSE, col.names = c("X","Y"))
x <- as.POSIXct(my_data$X, format="%m/%d/%Y")
x <- as.numeric(x)
attach(my_data)
#get summary of your data
summary(my_data)
#then plot your data
plot(x, my_data$Y, main = "Polynomial Regression", las=1)
#now, lets fit a linear regression
model1 <- lm(my_data$Y ~ x)
summary(model1)
#and add  the line to the plot... make it thick and red
abline(model1, lwd = 3, col="red")
#model2 <- lm(my_data$Y ~ my_data$X + I(my_data$X^2))
#summary(model2)
model2 <- lm(my_data$Y ~ poly(x, degree=2, row=T))
lines(smooth.spline(x, predict(model2)), col="blue", lwd=3)
anova(model1, model2)
b <- x^2
c <- x^3
model3 <- lm(my_data$Y ~ x + b + c)
summary(model2)
summary(model3)
my_data <- read.csv("test.csv", header=FALSE, col.names = c("X","Y"))
x <- as.POSIXct(my_data$X, format="%m/%d/%Y")
x <- as.numeric(x)
attach(my_data)
#get summary of your data
summary(my_data)
#then plot your data
plot(x, my_data$Y, main = "Polynomial Regression", las=1)
#now, lets fit a linear regression
model1 <- lm(my_data$Y ~ x)
summary(model1)
#and add  the line to the plot... make it thick and red
abline(model1, lwd = 3, col="red")
#model2 <- lm(my_data$Y ~ my_data$X + I(my_data$X^2))
#summary(model2)
model2 <- lm(my_data$Y ~ poly(x, degree=2, row=T))
lines(smooth.spline(x, predict(model2)), col="blue", lwd=3)
anova(model1, model2)
b <- x^2
c <- x^3
model3 <- lm(my_data$Y ~ x + b + c)
summary(model2)
summary(model3)
my_data <- read.csv("test.csv", header=FALSE, col.names = c("X","Y"))
x <- as.POSIXct(my_data$X, format="%m/%d/%Y")
x <- as.numeric(x)
attach(my_data)
#get summary of your data
summary(my_data)
#then plot your data
plot(x, my_data$Y, main = "Polynomial Regression", las=1)
#now, lets fit a linear regression
model1 <- lm(my_data$Y ~ x)
summary(model1)
#and add  the line to the plot... make it thick and red
abline(model1, lwd = 3, col="red")
#model2 <- lm(my_data$Y ~ my_data$X + I(my_data$X^2))
#summary(model2)
model2 <- lm(my_data$Y ~ poly(x, degree=2, row=T))
lines(smooth.spline(x, predict(model2)), col="blue", lwd=3)
anova(model1, model2)
b <- x^2
c <- x^3
model3 <- lm(my_data$Y ~ x + b + c)
summary(model2)
summary(model3)
my_data <- read.csv("test.csv", header=FALSE, col.names = c("X","Y"))
x <- as.POSIXct(my_data$X, format="%m/%d/%Y")
x <- as.numeric(x)
x
attach(my_data)
#get summary of your data
summary(my_data)
#then plot your data
plot(x, my_data$Y, main = "Polynomial Regression", las=1)
#now, lets fit a linear regression
model1 <- lm(my_data$Y ~ x)
summary(model1)
#and add  the line to the plot... make it thick and red
abline(model1, lwd = 3, col="red")
#model2 <- lm(my_data$Y ~ my_data$X + I(my_data$X^2))
#summary(model2)
model2 <- lm(my_data$Y ~ poly(x, degree=2, row=T))
lines(smooth.spline(x, predict(model2)), col="blue", lwd=3)
anova(model1, model2)
b <- x^2
c <- x^3
model3 <- lm(my_data$Y ~ x + b + c)
summary(model2)
summary(model3)
my_data <- read.csv("test.csv", header=FALSE, col.names = c("X","Y"))
x <- as.POSIXct(my_data$X, format="%m/%d/%Y")
x <- as.numeric(x)
x
attach(my_data)
#get summary of your data
summary(my_data)
#then plot your data
plot(x, my_data$Y, main = "Polynomial Regression", las=1)
#now, lets fit a linear regression
model1 <- lm(my_data$Y ~ x)
summary(model1)
#and add  the line to the plot... make it thick and red
abline(model1, lwd = 3, col="red")
#model2 <- lm(my_data$Y ~ my_data$X + I(my_data$X^2))
#summary(model2)
model2 <- lm(my_data$Y ~ poly(x, degree=2, row=T))
lines(smooth.spline(x, predict(model2)), col="blue", lwd=3)
anova(model1, model2)
b <- x^2
c <- x^3
model3 <- lm(my_data$Y ~ x + b + c)
summary(model2)
summary(model3)
my_data <- read.csv("test.csv", header=FALSE, col.names = c("X","Y"))
x <- as.POSIXct(my_data$X, format="%m/%d/%Y")
x <- as.numeric(x)
x
attach(my_data)
#get summary of your data
summary(my_data)
#then plot your data
plot(x, my_data$Y, main = "Polynomial Regression", las=1)
#now, lets fit a linear regression
model1 <- lm(my_data$Y ~ x)
summary(model1)
#and add  the line to the plot... make it thick and red
abline(model1, lwd = 3, col="red")
#model2 <- lm(my_data$Y ~ my_data$X + I(my_data$X^2))
#summary(model2)
model2 <- lm(my_data$Y ~ poly(x, degree=2, row=T))
lines(smooth.spline(x, predict(model2)), col="blue", lwd=3)
anova(model1, model2)
b <- x^2
c <- x^3
model3 <- lm(my_data$Y ~ x + b + c)
summary(model2)
lines(smooth.spline(x, predict(model3)), col="blue", lwd=3)
summary(model3)
my_data <- read.csv("test.csv", header=FALSE, col.names = c("X","Y"))
x <- as.POSIXct(my_data$X, format="%m/%d/%Y")
x <- as.numeric(x)
x
attach(my_data)
#get summary of your data
summary(my_data)
#then plot your data
plot(x, my_data$Y, main = "Polynomial Regression", las=1)
#now, lets fit a linear regression
model1 <- lm(my_data$Y ~ x)
summary(model1)
#and add  the line to the plot... make it thick and red
abline(model1, lwd = 3, col="red")
#model2 <- lm(my_data$Y ~ my_data$X + I(my_data$X^2))
#summary(model2)
model2 <- lm(my_data$Y ~ poly(x, degree=2, row=T))
lines(smooth.spline(x, predict(model2)), col="blue", lwd=3)
anova(model1, model2)
b <- x^2
c <- x^3
d <- x^4
model3 <- lm(my_data$Y ~ x + b + c)
model4 <- lm(my_data$Y ~ x + b + c + d)
summary(model2)
lines(smooth.spline(x, predict(model3)), col="blue", lwd=3)
lines(smooth.spline(x, predict(model4)), col="blue", lwd=3)
summary(model3)
my_data <- read.csv("test.csv", header=FALSE, col.names = c("X","Y"))
x <- as.POSIXct(my_data$X, format="%m/%d/%Y")
x <- as.numeric(x)
x
attach(my_data)
#get summary of your data
summary(my_data)
#then plot your data
plot(x, my_data$Y, main = "Polynomial Regression", las=1)
#now, lets fit a linear regression
model1 <- lm(my_data$Y ~ x)
summary(model1)
#and add  the line to the plot... make it thick and red
abline(model1, lwd = 3, col="red")
#model2 <- lm(my_data$Y ~ my_data$X + I(my_data$X^2))
#summary(model2)
model2 <- lm(my_data$Y ~ poly(x, degree=2, row=T))
lines(smooth.spline(x, predict(model2)), col="blue", lwd=3)
anova(model1, model2)
b <- x^2
c <- x^3
d <- x^4
model3 <- lm(my_data$Y ~ x + b + c)
model4 <- lm(my_data$Y ~ x + b + c + d)
summary(model2)
lines(smooth.spline(x, predict(model3)), col="blue", lwd=3)
lines(smooth.spline(x, predict(model4)), col="yellow", lwd=3)
summary(model4)
my_data <- read.csv("test.csv", header=FALSE, col.names = c("X","Y"))
x <- as.POSIXct(my_data$X, format="%m/%d/%Y")
x <- as.numeric(x)
x
attach(my_data)
#get summary of your data
summary(my_data)
#then plot your data
plot(x, my_data$Y, main = "Polynomial Regression", las=1)
#now, lets fit a linear regression
model1 <- lm(my_data$Y ~ x)
summary(model1)
#and add  the line to the plot... make it thick and red
abline(model1, lwd = 3, col="red")
#model2 <- lm(my_data$Y ~ my_data$X + I(my_data$X^2))
#summary(model2)
model2 <- lm(my_data$Y ~ poly(x, degree=2, row=T))
lines(smooth.spline(x, predict(model2)), col="blue", lwd=3)
anova(model1, model2)
b <- x^2
c <- x^3
d <- x^4
model3 <- lm(my_data$Y ~ x + b + c)
model4 <- lm(my_data$Y ~ x + b + c + d)
summary(model2)
lines(smooth.spline(x, predict(model3)), col="blue", lwd=3)
lines(smooth.spline(x, predict(model4)), col="yellow", lwd=3)
summary(model4)
summary(model2)
my_data <- read.csv("test.csv", header=FALSE, col.names = c("X","Y"))
x <- as.POSIXct(my_data$X, format="%m/%d/%Y")
x <- as.numeric(x)
x
attach(my_data)
#get summary of your data
summary(my_data)
#then plot your data
plot(x, my_data$Y, main = "Polynomial Regression", las=1)
#now, lets fit a linear regression
model1 <- lm(my_data$Y ~ x)
summary(model1)
#and add  the line to the plot... make it thick and red
abline(model1, lwd = 3, col="red")
#model2 <- lm(my_data$Y ~ my_data$X + I(my_data$X^2))
#summary(model2)
model2 <- lm(my_data$Y ~ poly(x, degree=2, row=T))
lines(smooth.spline(x, predict(model2)), col="blue", lwd=3)
anova(model1, model2)
b <- x^2
c <- x^3
d <- x^4
model3 <- lm(my_data$Y ~ x + b + c)
model4 <- lm(my_data$Y ~ x + b + c + d)
summary(model2)
lines(smooth.spline(x, predict(model3)), col="blue", lwd=3)
lines(smooth.spline(x, predict(model4)), col="yellow", lwd=3)
summary(model4)
summary(model2)
summary(model1)
my_data <- read.csv("test.csv", header=FALSE, col.names = c("X","Y"))
x <- as.POSIXct(my_data$X, format="%m/%d/%Y")
x <- as.numeric(x)
x
attach(my_data)
#get summary of your data
summary(my_data)
#then plot your data
plot(x, my_data$Y, main = "Polynomial Regression", las=1)
#now, lets fit a linear regression
model1 <- lm(my_data$Y ~ x)
summary(model1)
#and add  the line to the plot... make it thick and red
abline(model1, lwd = 3, col="red")
#model2 <- lm(my_data$Y ~ my_data$X + I(my_data$X^2))
#summary(model2)
model2 <- lm(my_data$Y ~ poly(x, degree=2, row=T))
lines(smooth.spline(x, predict(model2)), col="blue", lwd=3)
anova(model1, model2)
b <- x^2
c <- x^3
d <- x^4
model3 <- lm(my_data$Y ~ x + b + c)
model4 <- lm(my_data$Y ~ x + b + c + d)
summary(model2)
lines(smooth.spline(x, predict(model3)), col="blue", lwd=3)
lines(smooth.spline(x, predict(model4)), col="yellow", lwd=3)
summary(model4)
summary(model3)
summary(model2)
summary(model1)
my_data <- read.csv("test.csv", header=FALSE, col.names = c("X","Y"))
x <- as.POSIXct(my_data$X, format="%m/%d/%Y")
x <- as.numeric(x)
attach(my_data)
#get summary of your data
summary(my_data)
#then plot your data
plot(x, my_data$Y, main = "Polynomial Regression", las=1)
#now, lets fit a linear regression
model1 <- lm(my_data$Y ~ x)
summary(model1)
#and add  the line to the plot... make it thick and red
abline(model1, lwd = 3, col="red")
#2nd degree
model2 <- lm(my_data$Y ~ poly(x, degree=2, row=T))
lines(smooth.spline(x, predict(model2)), col="blue", lwd=3)
b <- x^2
c <- x^3
d <- x^4
model3 <- lm(my_data$Y ~ x + b + c)
model5 <- lm(my_data$Y ~ poly(x, degree=3, row=T))
model4 <- lm(my_data$Y ~ x + b + c + d)
summary(model2)
lines(smooth.spline(x, predict(model3)), col="blue", lwd=3)
lines(smooth.spline(x, predict(model4)), col="yellow", lwd=3)
lines(smooth.spline(x, predict(model5)), col="purple", lwd=3)
summary(model4)
summary(model3)
summary(model2)
summary(model1)
#statistics by jim making statistics intuitive //multicollinearity (nagkakataon)
my_data <- read.csv("test.csv", header=FALSE, col.names = c("X","Y"))
x <- as.POSIXct(my_data$X, format="%m/%d/%Y")
x <- as.numeric(x)
attach(my_data)
#get summary of your data
summary(my_data)
#then plot your data
plot(x, my_data$Y, main = "Polynomial Regression", las=1)
#now, lets fit a linear regression
model1 <- lm(my_data$Y ~ x)
summary(model1)
#and add  the line to the plot... make it thick and red
abline(model1, lwd = 3, col="red")
#2nd degree
model2 <- lm(my_data$Y ~ poly(x, degree=2, row=T))
lines(smooth.spline(x, predict(model2)), col="blue", lwd=3)
#3rd degree
b <- x^2
c <- x^3
model3 <- lm(my_data$Y ~ x + b + c)
lines(smooth.spline(x, predict(model3)), col="blue", lwd=3)
#4th degree
model4 <- lm(my_data$Y ~ x + b + c + d)
lines(smooth.spline(x, predict(model4)), col="yellow", lwd=3)
anova(model3, model4, model2)
#statistics by jim making statistics intuitive //multicollinearity (nagkakataon)
my_data <- read.csv("test.csv", header=FALSE, col.names = c("X","Y"))
x <- as.POSIXct(my_data$X, format="%m/%d/%Y")
x <- as.numeric(x)
attach(my_data)
#get summary of your data
summary(my_data)
#then plot your data
plot(x, my_data$Y, main = "Polynomial Regression", las=1)
#now, lets fit a linear regression
model1 <- lm(my_data$Y ~ x)
summary(model1)
#and add  the line to the plot... make it thick and red
abline(model1, lwd = 3, col="red")
#2nd degree
model2 <- lm(my_data$Y ~ poly(x, degree=2, row=T))
lines(smooth.spline(x, predict(model2)), col="blue", lwd=3)
#3rd degree
b <- x^2
c <- x^3
model3 <- lm(my_data$Y ~ x + b + c)
lines(smooth.spline(x, predict(model3)), col="blue", lwd=3)
#4th degree
d <- b^2
model4 <- lm(my_data$Y ~ x + b + c + d)
lines(smooth.spline(x, predict(model4)), col="yellow", lwd=3)
anova(model3, model4, model2)
#statistics by jim making statistics intuitive //multicollinearity (nagkakataon)
my_data <- read.csv("test.csv", header=FALSE, col.names = c("X","Y"))
x <- as.POSIXct(my_data$X, format="%m/%d/%Y")
x <- as.numeric(x)
attach(my_data)
#get summary of your data
summary(my_data)
#then plot your data
plot(x, my_data$Y, main = "Polynomial Regression", las=1)
#now, lets fit a linear regression
model1 <- lm(my_data$Y ~ x)
summary(model1)
#and add  the line to the plot... make it thick and red
abline(model1, lwd = 3, col="red")
#2nd degree
model2 <- lm(my_data$Y ~ poly(x, degree=2, row=T))
lines(smooth.spline(x, predict(model2)), col="blue", lwd=3)
#3rd degree
b <- x^2
c <- x^3
model3 <- lm(my_data$Y ~ x + b + c)
lines(smooth.spline(x, predict(model3)), col="blue", lwd=3)
#4th degree
d <- b^2
model4 <- lm(my_data$Y ~ x + b + c + d)
lines(smooth.spline(x, predict(model4)), col="yellow", lwd=3)
#4th degree
e <- c^2
model4 <- lm(my_data$Y ~ x + b + c + d + e)
lines(smooth.spline(x, predict(model5)), col="purple", lwd=3)
anova(model2, model3, model4)
#statistics by jim making statistics intuitive //multicollinearity (nagkakataon)
my_data <- read.csv("test.csv", header=FALSE, col.names = c("X","Y"))
x <- as.POSIXct(my_data$X, format="%m/%d/%Y")
x <- as.numeric(x)
attach(my_data)
#get summary of your data
summary(my_data)
#then plot your data
plot(x, my_data$Y, main = "Polynomial Regression", las=1)
#now, lets fit a linear regression
model1 <- lm(my_data$Y ~ x)
summary(model1)
#and add  the line to the plot... make it thick and red
abline(model1, lwd = 3, col="red")
#2nd degree
model2 <- lm(my_data$Y ~ poly(x, degree=2, row=T))
lines(smooth.spline(x, predict(model2)), col="blue", lwd=3)
#3rd degree
b <- x^2
c <- x^3
model3 <- lm(my_data$Y ~ x + b + c)
lines(smooth.spline(x, predict(model3)), col="blue", lwd=3)
#4th degree
d <- b^2
model4 <- lm(my_data$Y ~ x + b + c + d)
lines(smooth.spline(x, predict(model4)), col="yellow", lwd=3)
#4th degree
e <- c^2
model5 <- lm(my_data$Y ~ x + b + c + d + e)
lines(smooth.spline(x, predict(model5)), col="purple", lwd=3)
anova(model2, model3, model4, model5)
#statistics by jim making statistics intuitive //multicollinearity (nagkakataon)
my_data <- read.csv("testb.csv", header=FALSE, col.names = c("X","Y"))
x <- as.POSIXct(my_data$X, format="%m/%d/%Y")
x <- as.numeric(x)
attach(my_data)
#get summary of your data
summary(my_data)
#then plot your data
plot(x, my_data$Y, main = "Polynomial Regression", las=1)
#now, lets fit a linear regression
model1 <- lm(my_data$Y ~ x)
summary(model1)
#and add  the line to the plot... make it thick and red
abline(model1, lwd = 3, col="red")
#2nd degree
model2 <- lm(my_data$Y ~ poly(x, degree=2, row=T))
lines(smooth.spline(x, predict(model2)), col="blue", lwd=3)
#3rd degree
b <- x^2
c <- x^3
model3 <- lm(my_data$Y ~ x + b + c)
lines(smooth.spline(x, predict(model3)), col="blue", lwd=3)
#4th degree
d <- b^2
model4 <- lm(my_data$Y ~ x + b + c + d)
lines(smooth.spline(x, predict(model4)), col="yellow", lwd=3)
#4th degree
e <- c^2
model5 <- lm(my_data$Y ~ x + b + c + d + e)
lines(smooth.spline(x, predict(model5)), col="purple", lwd=3)
anova(model2, model3, model4, model5)
#statistics by jim making statistics intuitive //multicollinearity (nagkakataon)
my_data <- read.csv("testb.csv", header=FALSE, col.names = c("X","Y"))
attach(my_data)
#get summary of your data
summary(my_data)
#then plot your data
plot(x, my_data$Y, main = "Polynomial Regression", las=1)
#now, lets fit a linear regression
model1 <- lm(my_data$Y ~ x)
summary(model1)
#and add  the line to the plot... make it thick and red
abline(model1, lwd = 3, col="red")
#2nd degree
model2 <- lm(my_data$Y ~ poly(x, degree=2, row=T))
lines(smooth.spline(x, predict(model2)), col="blue", lwd=3)
#3rd degree
b <- x^2
c <- x^3
model3 <- lm(my_data$Y ~ x + b + c)
lines(smooth.spline(x, predict(model3)), col="blue", lwd=3)
#4th degree
d <- b^2
model4 <- lm(my_data$Y ~ x + b + c + d)
lines(smooth.spline(x, predict(model4)), col="yellow", lwd=3)
#4th degree
e <- c^2
model5 <- lm(my_data$Y ~ x + b + c + d + e)
lines(smooth.spline(x, predict(model5)), col="purple", lwd=3)
anova(model2, model3, model4, model5)
#statistics by jim making statistics intuitive //multicollinearity (nagkakataon)
